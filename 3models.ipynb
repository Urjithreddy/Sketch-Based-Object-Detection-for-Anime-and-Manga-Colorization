{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_image_pairs(dataset_dir):\n",
    "    bw_images = []\n",
    "    color_images = []\n",
    "    for filename in os.listdir(dataset_dir):\n",
    "        if filename.startswith(\"bw_image_\"):\n",
    "            bw_path = os.path.join(dataset_dir, filename)\n",
    "            color_filename = filename.replace(\"bw_image_\", \"color_image_\")\n",
    "            color_path = os.path.join(dataset_dir, color_filename)\n",
    "            if os.path.exists(color_path):\n",
    "                bw_images.append(bw_path)\n",
    "                color_images.append(color_path)\n",
    "            else:\n",
    "                print(f\"Colored image not found for: {filename}\")\n",
    "        elif filename.startswith(\"color_image_\"):\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"Skipping unrelated file: {filename}\")\n",
    "    return bw_images, color_images\n",
    "\n",
    "def preprocess_image(image_path, size=(256,256)):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = image.resize(size, Image.BILINEAR)\n",
    "        image = np.array(image).astype('float32')\n",
    "        image = image / 127.5 - 1.0\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def preprocess_dataset(bw_images, color_images, size=(256,256)):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for bw_path, color_path in zip(bw_images, color_images):\n",
    "        bw_im = preprocess_image(bw_path, size)\n",
    "        color_im = preprocess_image(color_path, size)\n",
    "        if bw_im is not None and color_im is not None:\n",
    "            inputs.append(bw_im)\n",
    "            targets.append(color_im)\n",
    "    return np.array(inputs), np.array(targets)\n",
    "\n",
    "def build_generator():\n",
    "    inp = layers.Input(shape=(256,256,3))\n",
    "    x = layers.Conv2D(64, 4, strides=2, padding='same')(inp)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.Conv2D(128, 4, strides=2, padding='same')(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.Conv2D(256, 4, strides=2, padding='same')(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.Conv2DTranspose(128, 4, strides=2, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2DTranspose(64, 4, strides=2, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    out = layers.Conv2DTranspose(3, 4, strides=2, padding='same', activation='tanh')(x)\n",
    "    return models.Model(inp, out, name=\"pix2pix_generator\")\n",
    "\n",
    "def build_discriminator():\n",
    "    inp = layers.Input(shape=(256,256,3))\n",
    "    tar = layers.Input(shape=(256,256,3))\n",
    "    merged = layers.Concatenate()([inp, tar])\n",
    "    x = layers.Conv2D(64, 4, strides=2, padding='same')(merged)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.Conv2D(128, 4, strides=2, padding='same')(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.Conv2D(256, 4, strides=2, padding='same')(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    out = layers.Conv2D(1, 4, strides=1, padding='same', activation='sigmoid')(x)\n",
    "    return models.Model([inp, tar], out, name=\"pix2pix_discriminator\")\n",
    "\n",
    "def build_patch_based_model():\n",
    "    inp = layers.Input(shape=(64,64,3))\n",
    "    x = layers.Conv2D(64, 4, strides=2, padding='same')(inp)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.Conv2D(128, 4, strides=2, padding='same')(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.Conv2DTranspose(128, 4, strides=2, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2DTranspose(64, 4, strides=2, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    out = layers.Conv2D(3, 3, strides=1, padding='same', activation='tanh')(x)\n",
    "    return models.Model(inp, out, name=\"patch_based_model\")\n",
    "\n",
    "def build_custom_model():\n",
    "    inp = layers.Input(shape=(256,256,3))\n",
    "    a = layers.Conv2D(64, 4, strides=2, padding='same')(inp)\n",
    "    a = layers.LeakyReLU(alpha=0.2)(a)\n",
    "    a = layers.Conv2D(128, 4, strides=2, padding='same')(a)\n",
    "    a = layers.LeakyReLU(alpha=0.2)(a)\n",
    "    a = layers.Conv2D(256, 4, strides=2, padding='same')(a)\n",
    "    a = layers.LeakyReLU(alpha=0.2)(a)\n",
    "    a_up = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(a)\n",
    "    a_up = layers.ReLU()(a_up)\n",
    "    b = layers.Conv2D(64, 3, strides=1, padding='same')(inp)\n",
    "    b = layers.ReLU()(b)\n",
    "    b = layers.Conv2D(128, 3, strides=2, padding='same')(b)\n",
    "    b = layers.ReLU()(b)\n",
    "    b = layers.Conv2D(256, 3, strides=2, padding='same')(b)\n",
    "    b = layers.ReLU()(b)\n",
    "    combined = layers.Concatenate()([a_up, b])\n",
    "    x = layers.Conv2DTranspose(128, 4, strides=2, padding='same')(combined)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2DTranspose(64, 4, strides=2, padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    out = layers.Conv2D(3, 3, strides=1, padding='same', activation='tanh')(x)\n",
    "    return models.Model(inp, out, name=\"custom_fused_model\")\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "l1_loss = tf.keras.losses.MeanAbsoluteError()\n",
    "\n",
    "def generator_loss(disc_generated_output, gen_output, target):\n",
    "    gan_loss = cross_entropy(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "    l1 = l1_loss(target, gen_output)\n",
    "    return gan_loss + 100 * l1\n",
    "\n",
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(disc_real_output), disc_real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "    return real_loss + fake_loss\n",
    "\n",
    "generator_optimizer = optimizers.Adam(5e-4, beta_1=0.5)\n",
    "discriminator_optimizer = optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "def extract_patches(images, patch_size=64):\n",
    "    patches = []\n",
    "    for img in images:\n",
    "        h, w = img.shape[0:2]\n",
    "        for i in range(0, h, patch_size):\n",
    "            for j in range(0, w, patch_size):\n",
    "                patch = img[i:i+patch_size, j:j+patch_size]\n",
    "                if patch.shape[0] == patch_size and patch.shape[1] == patch_size:\n",
    "                    patches.append(patch)\n",
    "    return np.array(patches)\n",
    "\n",
    "def stitch_patches(patches, original_shape):\n",
    "    patch_size = patches.shape[1]\n",
    "    h, w, _ = original_shape\n",
    "    stitched = np.zeros(original_shape)\n",
    "    patch_index = 0\n",
    "    for i in range(0, h, patch_size):\n",
    "        for j in range(0, w, patch_size):\n",
    "            stitched[i:i+patch_size, j:j+patch_size] = patches[patch_index]\n",
    "            patch_index += 1\n",
    "    return stitched\n",
    "\n",
    "@tf.function\n",
    "def train_pix2pix_step(input_image, target, generator, discriminator):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_output = generator(input_image, training=True)\n",
    "        disc_real_output = discriminator([input_image, target], training=True)\n",
    "        disc_gen_output = discriminator([input_image, gen_output], training=True)\n",
    "        gen_loss = generator_loss(disc_gen_output, gen_output, target)\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_gen_output)\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    return gen_loss, disc_loss\n",
    "\n",
    "def train_pix2pix(dataset, generator, discriminator, epochs=100):\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Starting epoch {epoch+1}/{epochs} ...\")\n",
    "        for input_image, target in dataset:\n",
    "            g_loss, d_loss = train_pix2pix_step(input_image, target, generator, discriminator)\n",
    "        print(f\"Epoch {epoch+1} completed. Generator Loss: {g_loss:.4f} Disc Loss: {d_loss:.4f}\")\n",
    "\n",
    "def train_patch_based_model(input_imgs, target_imgs, model, epochs=100):\n",
    "    in_patches = extract_patches(input_imgs, patch_size=64)\n",
    "    tar_patches = extract_patches(target_imgs, patch_size=64)\n",
    "    print(\"Training patch–based model on patches with shapes:\", in_patches.shape, tar_patches.shape)\n",
    "    model.compile(optimizer=optimizers.Adam(2e-4, beta_1=0.5), loss='mae')\n",
    "    model.fit(in_patches, tar_patches, batch_size=32, epochs=epochs)\n",
    "\n",
    "def train_custom_model(input_imgs, target_imgs, model, epochs=100):\n",
    "    print(\"Training custom fused model on full images:\", input_imgs.shape, target_imgs.shape)\n",
    "    model.compile(optimizer=optimizers.Adam(5e-4), loss='mae')\n",
    "    model.fit(input_imgs, target_imgs, batch_size=1, epochs=epochs)\n",
    "\n",
    "def compute_ssim(pred, target):\n",
    "    pred_denorm = (pred + 1) / 2.0\n",
    "    target_denorm = (target + 1) / 2.0\n",
    "    pred_denorm = tf.convert_to_tensor(pred_denorm, dtype=tf.float32)\n",
    "    target_denorm = tf.convert_to_tensor(target_denorm, dtype=tf.float32)\n",
    "    ssim_val = tf.reduce_mean(tf.image.ssim(pred_denorm, target_denorm, max_val=1.0))\n",
    "    return ssim_val * 100.0\n",
    "\n",
    "def test_models(test_bw_path, test_color_path, generator, patch_model, custom_model):\n",
    "    test_input = preprocess_image(test_bw_path, size=(256,256))\n",
    "    test_target = preprocess_image(test_color_path, size=(256,256))\n",
    "    if test_input is None or test_target is None:\n",
    "        print(\"Error: Unable to load test images.\")\n",
    "        return\n",
    "    test_input_batch = np.expand_dims(test_input, axis=0)\n",
    "    pix2pix_output = generator.predict(test_input_batch)[0]\n",
    "    patches = extract_patches(np.expand_dims(test_input, axis=0), patch_size=64)\n",
    "    pred_patches = patch_model.predict(patches)\n",
    "    patch_based_output = stitch_patches(pred_patches, test_input.shape)\n",
    "    custom_output = custom_model.predict(test_input_batch)[0]\n",
    "    ssim_pix = compute_ssim(pix2pix_output, test_target)\n",
    "    ssim_patch = compute_ssim(patch_based_output, test_target)\n",
    "    ssim_custom = compute_ssim(custom_output, test_target)\n",
    "    print(f\"Pix2Pix model SSIM accuracy: {ssim_pix.numpy():.2f}%\")\n",
    "    print(f\"Patch–based model SSIM accuracy: {ssim_patch.numpy():.2f}%\")\n",
    "    print(f\"Custom fused model SSIM accuracy: {ssim_custom.numpy():.2f}%\")\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(1,4,1)\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.imshow(((test_input+1)/2))\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,4,2)\n",
    "    plt.title(\"Pix2Pix Output\")\n",
    "    plt.imshow(((pix2pix_output+1)/2))\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,4,3)\n",
    "    plt.title(\"Patch-based Output\")\n",
    "    plt.imshow(((patch_based_output+1)/2))\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,4,4)\n",
    "    plt.title(\"Custom Fused Output\")\n",
    "    plt.imshow(((custom_output+1)/2))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset_dir = \"smalldatasetmanga\"\n",
    "    print(\"Dataset directory exists:\", os.path.exists(dataset_dir))\n",
    "    print(\"Files in dataset directory:\", os.listdir(dataset_dir))\n",
    "    bw_files, color_files = load_image_pairs(dataset_dir)\n",
    "    print(\"Number of BW images:\", len(bw_files), \"and colored images:\", len(color_files))\n",
    "    inputs, targets = preprocess_dataset(bw_files, color_files, size=(256,256))\n",
    "    print(\"Inputs shape:\", inputs.shape, \"Targets shape:\", targets.shape)\n",
    "    pix2pix_generator = build_generator()\n",
    "    pix2pix_discriminator = build_discriminator()\n",
    "    patch_based_model = build_patch_based_model()\n",
    "    custom_fused_model = build_custom_model()\n",
    "    pix2pix_dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(10).batch(1)\n",
    "    print(\"Training Pix2Pix model ...\")\n",
    "    train_pix2pix(pix2pix_dataset, pix2pix_generator, pix2pix_discriminator, epochs=100)\n",
    "    print(\"Training patch–based model ...\")\n",
    "    train_patch_based_model(inputs, targets, patch_based_model, epochs=100)\n",
    "    print(\"Training custom fused model ...\")\n",
    "    train_custom_model(inputs, targets, custom_fused_model, epochs=100)\n",
    "    test_bw_path = os.path.join(dataset_dir, \"bw_image_6.png\")\n",
    "    test_color_path = os.path.join(dataset_dir, \"color_image_6.png\")\n",
    "    test_models(test_bw_path, test_color_path, pix2pix_generator, patch_based_model, custom_fused_model)\n",
    "    pix2pix_generator.save(\"pix2pix_generator_256.h5\")\n",
    "    pix2pix_discriminator.save(\"pix2pix_discriminator_256.h5\")\n",
    "    patch_based_model.save(\"patch_based_model_256.h5\")\n",
    "    custom_fused_model.save(\"custom_fused_model_256.h5\")\n",
    "    print(\"Models saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
